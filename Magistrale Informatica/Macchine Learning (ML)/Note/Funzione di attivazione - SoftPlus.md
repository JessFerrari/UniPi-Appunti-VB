---
Course: "[[Machine Learning (ML)]]"
tags:
  - IA
Area: "[[Reti Neurali (NN)]]"
topic: 
SubTopic:
---
# Funzione di attivazione - SoftPlus
---
la __[[Funzioni di attivazione|funzione di attivazione]] softPlus__ è una approssimazione continua della funzione [[Funzione di attivazione - ReLu|relu]] ed è definita come $$f(x)=\ln(1+e^x)$$![[Pasted image 20241227064938.png]]