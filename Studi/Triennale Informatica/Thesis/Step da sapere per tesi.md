
Concetti generali del ML:
- [x] introduzione al [[Machine Learning (ML)|ML]] classico 
- [x] introduzione al [[Machine Learning (ML)|ML]] con reti neurali
- [x] Capire meglio gli algoritmi di Linear regression 

macchine learning con sakit-learn: 
- [ ] leggere qualcosa sul framework
- [ ] Capire come fare la regressione lineare e usarla come output del modello


Test Machine learning con keras:
- [x] studio framework keras
	- [x] capire come creare un nuovo layer
- [x] scaricare i dataset 
- [x] Fare qualche test su qualche dataset per provare

Sperimentazione ESN:
- [x]  Leggere paper originale su echo state network
- [x] Approfondire Reservoir computing
	- [x] capire le echo state network (ESN)
- [x] criteri di stabilita trovabili in [[Re-visiting the echo state property.pdf|questo paper]] o una formulazione equivalente [[A tighter bound for the echo state property.pdf|qui]]
	- [x] capire come generare matrici che rispettano il criterio di stabilità
	- [x] Sperimentazione [[Note Sperimentazione Stabilita criterio per echo state proerty| in questa nota]]
	- [x] Capire come portarlo al edge of stability
	- [x] Fare esperimenti sul utilità di questo (a quanto letto non necessariamente è una cosa positiva)
- [x] seguire stesso schema di normalizzazione e encoding dei dati 
- [x] Fare qualche esperimento per avere dei confronti


Sviluppo LRMU (Legandre Reservoir memory unit): 
- [x] Leggere paper sulle LMU
- [x] capire come funziona in codice la cella di memoria LMU
	- [x] Re implementazione Del layer LMU
	- [x] Validare che il modello implementato sia equivalente
- [x] Capire che dataset usare per la sperimentazione
- [x]  sperimentare il layer con diverse configurazioni di cosa sia trainabile e cosa no



Scrittura
- [ ] motivazione
- [ ] Itroduzione teorica
- [ ] Spegazione di cosa si è fatto
- [ ] Risutati
- [ ]  Conclusioni

